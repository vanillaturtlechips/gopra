해당 문제를 확인하기 위해 TCP sockert 프로그래밍을 구현하였습니다. Linux ubuntu 24.04 & GOlang을 통해 작성되으므로 참고 부탁드립니다.

 https://github.com/vanillaturtlechips/TcpSocektPro#

##

본 문서의 목적은 다양한 네트워크 이상으로 인해 발생하는 애플리케이션의 의도하지 않은 동작을 방지하여 시스템의 안정성과 신뢰성에 영향을 미치는 일을 줄이는 데 있다.

이 문서는 TCP의 기본 사항은 다루지 않으며, 주로 TCP 네트워크 프로그래밍 실제에서 발생할 수 있는 문제와 이에 대한 실제로 검증된 해결책을 요약한다. 이 문서의 세부 내용 중 상당 부분이 주로 Linux 시스템에 초점을 맞추고 있지만, 대부분의 권장 사항은 모든 시스템에 적합하다.

## 1. 서버 측 리스너에 SO_REUSEADDR 옵션 설정

이 옵션은 서버 프로그램이 갑자기 종료되거나 재시작될때 유용하다. 

서버 측 애플리케이션을 재시작할 때, **address already in use**와 같은 오류 메시지가 발생할 수 있다. 이는 해당 주소가 이미 사용 중이어서 애플리케이션을 빠르고 성공적으로 재시작할 수 없음을 의미합니다. 이전 프로세스는 종료되었는데 왜 아직도 'address already in use' 오류가 발생할까?

다음 두 가지 사항을 이해해야 한다.
 - TCP 커넥션을 능동적으로 닫는 쪽(Active Close)에 2MSL 동안 지속되는 TIME_WAIT 상태가 존재한다.
 - TCP 연결은 4-Tuple <local addr, local port, remote addr, remote port>로 결정된다.

<img width="534" height="256" alt="image" src="https://github.com/user-attachments/assets/698df0cb-92d4-43b1-a425-f6c19689ec3a" />

 먼저 TCP 연결 종료 시 TIME_WAIT 상태에 대해 간략하게 살펴본다.
 - 연결 상태 유지를 통해 TCP 연결이 신뢰성 있게 종료될 수 있도록 한다. 능동적으로 종료하는 측이 보낸 마지막 ack가 손실되면, 수동적으로 종료하는 측은 FIN 메세지를 재전송한다. TIME_WAIT 상태가 없고, 마지막 ACK가 손실된다면, 수동적 종료측은 한동안 LAST_ACK 상태로 남아 재전송을 기다리게 된다.
만약 능동적 종료 측이 새로운 TCP 연결을 생성하고 우연히 동일한 4-Tuple을 사용하면, 연결 생성이 실패하고 상대방에 의해 리셋될 수 있다.
 - 오래된 중복 메세지가 네트워크에서 소멸될 때까지 기다려서 동일한 4-Tuple을 사용하는 새로운 TCP 연결을 방해하는 것을 방지한다. 오래된 메세지의 시퀸스 번호가 새 연결의 수신 원도우 내에 우연히 포함될 수 있다.

TCP 메세지당 최대 생존 시간은 MSL이며, 왕복 시간은 최대 2*MSL 이므로 TIME_WAIT는 2MSL을 기다려야 한다.

프로세스가 종료되면, 연결의 능동적인 종료를 시작하고 연결은 결국 TIME_WAIT 상태가 된다. 새 프로세스 포트에 bind하고 listen을 시도할 때, local port에 해당되는 연결이 여전히 TIME_WAIT 상태에 있기 때문에 오류가 보고된다.

실제로는 새로운 TCP 연결이 이전 TCP 연결의 4-Tuple이 동일하고, 이전 maze의 sequence number가 새 연결의 수신 윈도우 내에 들어올 때만 간섭이 발생한다. TIME_WAIT 상태의 포트를 사용하기 위해 대부분의 시스템 구현은 관련 개선 및 확장을 가지고 있다.

- 새 연결의 syn에 의해 알려진 초기 sequence number는 TIME_WAIT 상태에 있는 이전 연결의 sequence number보다 커야 한다. 이는 이전 연결의 message sequence number와 겹치지 않도록 어느 정도 보장할 수 있다.
- TCP timestamps extension option 이 커져 있으면, 새 연결의 timestamp는 TIME_WAIT 상태에 있는 이전 연결의 timestamp보다 커야 한다. 이는 이전 연결의 메세지가 새 연결에 영향을 미치지 않도록 보장한다.

```
새 연결의 초기 시퀸스 넘버 > TIME_WAIT에 있는 이전 연결의 시퀸스 번호
TCP 타임스탬프 확장 옵션이 켜져 있으면, 새 연결의 타임스탬프 > 이전 연결의 타임스탬프
```
따라서, TCP 타임스탬프 확장 옵션이 켜져 있을 때 (시스템 매개변수 net.ipv4.tcp_timestamps = 1), SO_REUSEADDR 옵션을 안전하게 설정하여 빠른 프로그램 재시작을 지원할 수 있다.

<img width="675" height="69" alt="image" src="https://github.com/user-attachments/assets/b6d46ff8-730c-47ac-af49-972205bb3b6e" />

이것을 시스템 매개변수인 `net.ipv4.tcp_tw_reuse`와 혼동하지 않도록 주의해야 한다. `net.ipv4.tcp_tw_reuse`는 클라이언트가 connect를 호출하여 연결이 생성할 때만 적용되며, 1초 이상의 TIME_WAIT 상태인 포트에 대해 사용될 수 있다. (last ack 손실 방지).
반면, SO_REUSEADDR은 bind 포트에 적용되며, 일반적으로 서버가 listen 될때 사용된다. 따라서 이는 로컬의 비-Listen 상태 포트를 사용할 수 있게 한다. (다른 포트도 SO_REUSEADDR을 설정해야 함). 

물론 단순하게 TIME WAIT 상태의 포트만 사용할 수 있게 하는 것이 아니다.

## 2. 애플리케이션 리스닝 포트 규격 설정 및 준수

각 애플리케이션과 통신 프로토콜은 고정되고 통일된 리스닝 포트를 가져야 한다. 이는 회사 내에서 합의를 형성하고, 협업 비용을 줄이며, 운영 및 유지보수(O&M) 효율성을 높이는 데 편리하다. 그러니까 일부 네트워크 acl control에 경우, 표준화되고 통일된 포트는 O&M에 큰 편의성을 제공한다.

애플리케이션 리스닝 포트는 `net.ipv4.ip_local_port_range` 범위 내에 있으면 절대 안된다. 이 범위는 OS가 local port number를 자동으로 할당하는데 사용된다. (bind 또는 connect 시 포트 번호가 지정되지 않은 경우), Linux 시스템의 기본값은 [32768, 60999]이다. 현재 앱 서버 인스턴스(VM&K8S pod) 등은 애플리케이션 프로세스 자체 뿐만 아니라 모니터링 수집, 사이드카 에이전트와 같은 프로세스도 포함할 수 있다. 

`net.ipv4.ip_local_port_range` 범위 내의 포트를 리스닝 포트로 선택되면, 해당 포트는 애플리케이션 프로세스가 시작되지 전에 다른 프로세스의 TCP 연결에 이미 자동으로 할당되어 있을 가능성이 높다. 이로 인해 리스닝 포트의 바인딩이 실패하여 프로세스 시작이 실패할 수 있다. 물론 이미 할당된 포트가 SO_REUSEDDR로 설정되어 있다면 애플리케이션이 리스닝 포트에 바인딩하는데 실패하진 않겠지만, 이러한 임시 포트는 일반적으로 그러한 설정이 되어있지 않는다. 만약 `net.ipv4.ip_local_port_range` 범위 내에 포트를 리스닝해야 할 필요가 있다면 ( 예: 예약된 타사 시스템의 기본 포트 ) 

`net.ipv4.ip_local_reserved_ports`의 시스템 매개변수를 설정하여 예약할 수 있으며, 예약된 포트는 자동으로 할당되지 않는다. 그러나 이는 O&M을 위해 시스템 제공을 더 어렵게 만들 수 있으므로 권장되지 않는다. 

그러니까 모든 유형의 애플리케이션 및 통신 프로토콜의 리스닝 포트는 표준화되어 9000 미만으로 설정하는게 좋다!

(쿠버네티스의 클러스터 ip의 할당 범위는 30000-32767이다)
<img width="728" height="44" alt="image" src="https://github.com/user-attachments/assets/988be341-0cd4-4bed-8798-d34b89f61e2e" />

## 3. 애플리케이션 서비스 포트와 관리 포트의 분리

서비스 포트는 비즈니스 요청 처리 포트이며, 관리 포트는 프레임워크 또는 애플리케이션을 위한 관리 요청 처리 포트이다. (ex: 서비스 등록 온라인/오프라인) Spring boot를 예로 들면, 애플리케이션 포트는 server.port에 해당되고 관리 포트는 management.port에 해당된다.

애플리케이션의 서비스 포트와 관리 포트를 분리하는 것은 다음과 같은 이점이 있다.
- 비즈니스 요청과 관리 요청이 서로 영향을 미치는 것을 방지한다. (ex. therad pulling)
- 권한 관리, ACL 제어를 가능하게 한다. 관리 포트는 일반적으로 애플리케이션의 핵심 동작을 제어할 수 있으므로, 엄격한 권한 관리 및 ACL 제어가 필요하다. (ex 방화벽을 통해 특정 포트에 액세스 하도록 허용)

비즈니스 애플리케이션의 HTTP 서비스 포트와 관리 포트가 동일하다고 치면, 애플리케이션의 동일한 인스턴스가 내부 논리 문제로 인해 교착 상태에 빠져  `the request blocking timeout`을 일으킨다. 하지만 이 때 서비스 등록 상태 유지 스레드는 여전히 정상이기 때문에, 클라이언트는 여전히 이 예외 인스턴스에 요청을 보내는 문제가 발새한다. 

이 시점에서 문제 해결을 위해 인스턴스를 시버스 등록에서 오프라인으로 전환하고, 프로세스를 유지해야 하지만, 비즈니스 스레드 차단으로 인해 HTTP thread pool의 모든 스레드가 차단되었고, 이는 관리 모듈 스레드가 HTTP 서비스 등록 오프라인 요청을 처리할 수 없게 하여, 결국 정상적으로 오프라인으로 전환할 수 없게 된다.

그래서 이러한 문제가 재발하는 것을 방지하기 위해 애플리케이션 서비스 포트와 관리 포트를 분리하고, 스레드 풀 격리를 구현해야 한다. 물론 Fusion 같은 다른 메커니즘도 개별 인스턴스를 예외 처리하는데 도움이 되지만, 포트 분리가 중점이다.

## 4. 연결 설정에 타임아웃 설정

네트워크 정체, IP 도달 불가능, 핸드셰이크 큐 가득 참 등의 상황에서 연결 설정이 차단되고 타임아웃될 수 있다. 앱에서 예측 불가능한 차단 시간을 피하기 위해, 타임아웃 제어를 위해 연결을 설정할 때 타임아웃 시간을 설정하는게 좋다. 능동적인 설정이 없다면, 타임아웃 시간은 시스템의 기본 동작에 의해 제어되는데 이는 모든 앱 시나리오에 충분하지 않을 수 있다. (참고: 핸드셰이크 큐가 가득 찼을 때 시스템 매개변수 `net.ipv4.tcp_abort_on_overflow`가 설정되어 있으면 연결이 즉시 리셋된다.) 

시스템이 기본적으로 연결 설정 타임아웃을 어떻게 제어하는지 살펴보자.

- TCP 3-way 핸드셰이크의 첫 번째 SYN 메시지가 ACK를 받지 못하면, 시스템은 자동으로 SYN 메시지를 재시도한다. 최대 재시도 횟수는 시스템 매개변수 **net.ipv4.tcp_syn_retries**에 의해 제어되며, 기본값은 6이다. 초기 RTO는 1초이며, SYN ACK를 받지 못하면 순서대로 1초, 2초, 4초, 8초, 16초, 32초를 기다린 후 재전송을 시작하고, 마지막 재전송은 64초를 기다린 후 포기한다. 결국 127초 후에 ETIMEOUT 타임아웃 오류를 반환한다.

<img width="703" height="48" alt="image" src="https://github.com/user-attachments/assets/b84d5f76-bc3c-42f5-b225-7efe836abc7d" />

특정 회사의 비즈니스 시나리오에 따라 `net.ipv4.tcp_syn_retries` 시스템 매개변수를 조정하여 보장하는 것이 좋다. (ex: 매개변수를 3으로 설정하여 최대 15초 내외에서 타임아웃 오류를 반환하도록 권장하는 의견)

## 5. 애플리케이션 계층 하트비트를 사용한 연결 상태 확인

TCP 연결에 예외가 발생하면, 우리는 가능한 빨리 이를 감지하고 이에 따라 예외를 처리하고 복구해야 한다. FIN 또는 RST와 같은 연결 종료 및 리셋 시나리오에서는 애플리케이션 계층에서 빠르게 감지할 수 있다. 그러나 피어 머신의 전원 차단, 네트워크 케이블의 물리적 분리, 네트워크 장비 이상으로 발생하는 `false connections`의 경우 특별한 조치가 없으면 애플리케이션 계층에서 오랫동안 감지하지 못할 수 있다.

네트워크 이상 감지와 관련하여 가장 먼저 떠오르는 것은 아마도 TCP Keepalive일 것이다. 시스템 TCP Keepalive와 관련된 세가지 매개변수는 `net.ipv4.tcp_keepalive_time, net.ipv4.tcp_keepalive_intvl, net.ipv4.tcp_keepalive_probes`이며 기본값은 각각 7200초, 75초, 9번이다. 즉, 7200초 동안 상대방으로부터 데이터를 받지 못하면 TCP Keepalive 메시지를 전송하기 시작하고, 75초 내에 응답이 없으면 모든 9번의 재시도가 실패할 때까지 재시도를 계속한 후 애플리케이션 계층 오류 메시지를 반환한다.

<img width="752" height="139" alt="image" src="https://github.com/user-attachments/assets/d2013be1-bf0d-472f-a817-62ca54062274" />

왜 애플리케이션 계층 하트비트 검사를 구현해야 할까? 시스템의 TCP Keepalive로는 요구 사항을 충족할 수 없을까? 그렇다. 시스템의 TCP Keepalive는 기본 방어 솔루션으로만 사용될 수 있으며, 높은 안정성과 높은 신뢰성 시나리오의 요구 사항을 충족할 수 없다. 그 이유는 다음과 같다.

- TCP Keepalive는 익스텐션 옵션으로, 모든 장치가 지원하지 않을 수 있다.
- TCP Keepalive 메시지는 캐리어 장비와 같은 장치에 의해 의도적으로 필터링되거나 차단될 수 있다.
- TCP Keepalive는 애플리케이션 계층 상태 (예: 프로세스 차단, 교착 상태, TCP 버퍼 가득 참 등)를 감지할 수 없다.
- TCP Keepalive는 TCP 재전송 제어와 충돌하기 쉬워 실패로 이어질 수 있다.

TCP 상태가 애플리케이션 계층 상태를 반영하지 않는 문제에 대해 간략히 설명한다. 첫 번째 시나리오는 TCP 연결 설정이 성공했다고 해서 상대방 애플리케이션이 연결을 감지했다는 의미가 아니다. 왜냐하면 TCP 3-way 핸드셰이크는 커널에서 완료되며, 연결이 설정되었더라도 상대방이 **Accept**를 전혀 하지 않았을 수도 있기 때문이다. 따라서 일부 시나리오에서는 TCP 연결이 성공적으로 설정될 수 있는지 여부만으로 상대방 애플리케이션의 상태를 판단하는 것은 정확하지 않으며, 이 시나리오로는 프로세스의 생존 여부만 감지할 수 있다. 

다른 시나리오는 로컬 TCP 쓰기 작업이 성공했지만, 데이터가 여전히 로컬 쓰기 버퍼, 네트워크 링크 장치 또는 상대방의 읽기 버퍼에 있을 수 있으며, 이는 상대방 애플리케이션이 데이터를 읽었다는 의미도 아니다.

여기서는 TCP Keepalive와 TCP 재전송 간의 충돌에 중점을 두자. Linux 시스템은 `net.ipv4.tcp_retries2` 매개변수를 통해 TCP 타임아웃 재전송 횟수를 제어하며, 이는 TCP 타임아웃 시간에 영향을 미친다. 초기 RTO는 TCP_RTO_MIN (200ms)이며, RTO는 지수적 양보를 하며, 최대 RTO는 TCP_RTO_MAX (2분)이다. net.ipv4.tcp_retries2의 기본값은 15이며, 대략 924.6초의 타임아웃을 의미한다.

<img width="653" height="47" alt="image" src="https://github.com/user-attachments/assets/a96865a2-9732-4c5d-8ba0-ffc183aefde9" />


