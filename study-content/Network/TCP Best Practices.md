해당 문제를 확인하기 위해 TCP sockert 프로그래밍을 구현하였습니다. Linux ubuntu 24.04 & GOlang을 통해 작성되으므로 참고 부탁드립니다.

 https://github.com/vanillaturtlechips/TcpSocektPro#

##

본 문서의 목적은 다양한 네트워크 이상으로 인해 발생하는 애플리케이션의 의도하지 않은 동작을 방지하여 시스템의 안정성과 신뢰성에 영향을 미치는 일을 줄이는 데 있다.

이 문서는 TCP의 기본 사항은 다루지 않으며, 주로 TCP 네트워크 프로그래밍 실제에서 발생할 수 있는 문제와 이에 대한 실제로 검증된 해결책을 요약한다. 이 문서의 세부 내용 중 상당 부분이 주로 Linux 시스템에 초점을 맞추고 있지만, 대부분의 권장 사항은 모든 시스템에 적합하다.

## 1. 서버 측 리스너에 SO_REUSEADDR 옵션 설정

이 옵션은 서버 프로그램이 갑자기 종료되거나 재시작될때 유용하다. 

서버 측 애플리케이션을 재시작할 때, **address already in use**와 같은 오류 메시지가 발생할 수 있다. 이는 해당 주소가 이미 사용 중이어서 애플리케이션을 빠르고 성공적으로 재시작할 수 없음을 의미합니다. 이전 프로세스는 종료되었는데 왜 아직도 'address already in use' 오류가 발생할까?

다음 두 가지 사항을 이해해야 한다.
 - TCP 커넥션을 능동적으로 닫는 쪽(Active Close)에 2MSL 동안 지속되는 TIME_WAIT 상태가 존재한다.
 - TCP 연결은 4-Tuple <local addr, local port, remote addr, remote port>로 결정된다.

<img width="534" height="256" alt="image" src="https://github.com/user-attachments/assets/698df0cb-92d4-43b1-a425-f6c19689ec3a" />

 먼저 TCP 연결 종료 시 TIME_WAIT 상태에 대해 간략하게 살펴본다.
 - 연결 상태 유지를 통해 TCP 연결이 신뢰성 있게 종료될 수 있도록 한다. 능동적으로 종료하는 측이 보낸 마지막 ack가 손실되면, 수동적으로 종료하는 측은 FIN 메세지를 재전송한다. TIME_WAIT 상태가 없고, 마지막 ACK가 손실된다면, 수동적 종료측은 한동안 LAST_ACK 상태로 남아 재전송을 기다리게 된다.
만약 능동적 종료 측이 새로운 TCP 연결을 생성하고 우연히 동일한 4-Tuple을 사용하면, 연결 생성이 실패하고 상대방에 의해 리셋될 수 있다.
 - 오래된 중복 메세지가 네트워크에서 소멸될 때까지 기다려서 동일한 4-Tuple을 사용하는 새로운 TCP 연결을 방해하는 것을 방지한다. 오래된 메세지의 시퀸스 번호가 새 연결의 수신 원도우 내에 우연히 포함될 수 있다.

TCP 메세지당 최대 생존 시간은 MSL이며, 왕복 시간은 최대 2*MSL 이므로 TIME_WAIT는 2MSL을 기다려야 한다.

프로세스가 종료되면, 연결의 능동적인 종료를 시작하고 연결은 결국 TIME_WAIT 상태가 된다. 새 프로세스 포트에 bind하고 listen을 시도할 때, local port에 해당되는 연결이 여전히 TIME_WAIT 상태에 있기 때문에 오류가 보고된다.

실제로는 새로운 TCP 연결이 이전 TCP 연결의 4-Tuple이 동일하고, 이전 maze의 sequence number가 새 연결의 수신 윈도우 내에 들어올 때만 간섭이 발생한다. TIME_WAIT 상태의 포트를 사용하기 위해 대부분의 시스템 구현은 관련 개선 및 확장을 가지고 있다.

- 새 연결의 syn에 의해 알려진 초기 sequence number는 TIME_WAIT 상태에 있는 이전 연결의 sequence number보다 커야 한다. 이는 이전 연결의 message sequence number와 겹치지 않도록 어느 정도 보장할 수 있다.
- TCP timestamps extension option 이 커져 있으면, 새 연결의 timestamp는 TIME_WAIT 상태에 있는 이전 연결의 timestamp보다 커야 한다. 이는 이전 연결의 메세지가 새 연결에 영향을 미치지 않도록 보장한다.

```
새 연결의 초기 시퀸스 넘버 > TIME_WAIT에 있는 이전 연결의 시퀸스 번호
TCP 타임스탬프 확장 옵션이 켜져 있으면, 새 연결의 타임스탬프 > 이전 연결의 타임스탬프
```
따라서, TCP 타임스탬프 확장 옵션이 켜져 있을 때 (시스템 매개변수 net.ipv4.tcp_timestamps = 1), SO_REUSEADDR 옵션을 안전하게 설정하여 빠른 프로그램 재시작을 지원할 수 있다.

<img width="675" height="69" alt="image" src="https://github.com/user-attachments/assets/b6d46ff8-730c-47ac-af49-972205bb3b6e" />

이것을 시스템 매개변수인 `net.ipv4.tcp_tw_reuse`와 혼동하지 않도록 주의해야 한다. `net.ipv4.tcp_tw_reuse`는 클라이언트가 connect를 호출하여 연결이 생성할 때만 적용되며, 1초 이상의 TIME_WAIT 상태인 포트에 대해 사용될 수 있다. (last ack 손실 방지).
반면, SO_REUSEADDR은 bind 포트에 적용되며, 일반적으로 서버가 listen 될때 사용된다. 따라서 이는 로컬의 비-Listen 상태 포트를 사용할 수 있게 한다. (다른 포트도 SO_REUSEADDR을 설정해야 함). 

물론 단순하게 TIME WAIT 상태의 포트만 사용할 수 있게 하는 것이 아니다.

## 2. 애플리케이션 리스닝 포트 규격 설정 및 준수

각 애플리케이션과 통신 프로토콜은 고정되고 통일된 리스닝 포트를 가져야 한다. 이는 회사 내에서 합의를 형성하고, 협업 비용을 줄이며, 운영 및 유지보수(O&M) 효율성을 높이는 데 편리하다. 그러니까 일부 네트워크 acl control에 경우, 표준화되고 통일된 포트는 O&M에 큰 편의성을 제공한다.

애플리케이션 리스닝 포트는 `net.ipv4.ip_local_port_range` 범위 내에 있으면 절대 안된다. 이 범위는 OS가 local port number를 자동으로 할당하는데 사용된다. (bind 또는 connect 시 포트 번호가 지정되지 않은 경우), Linux 시스템의 기본값은 [32768, 60999]이다. 현재 앱 서버 인스턴스(VM&K8S pod) 등은 애플리케이션 프로세스 자체 뿐만 아니라 모니터링 수집, 사이드카 에이전트와 같은 프로세스도 포함할 수 있다. 

`net.ipv4.ip_local_port_range` 범위 내의 포트를 리스닝 포트로 선택되면, 해당 포트는 애플리케이션 프로세스가 시작되지 전에 다른 프로세스의 TCP 연결에 이미 자동으로 할당되어 있을 가능성이 높다. 이로 인해 리스닝 포트의 바인딩이 실패하여 프로세스 시작이 실패할 수 있다. 물론 이미 할당된 포트가 SO_REUSEDDR로 설정되어 있다면 애플리케이션이 리스닝 포트에 바인딩하는데 실패하진 않겠지만, 이러한 임시 포트는 일반적으로 그러한 설정이 되어있지 않는다. 만약 `net.ipv4.ip_local_port_range` 범위 내에 포트를 리스닝해야 할 필요가 있다면 ( 예: 예약된 타사 시스템의 기본 포트 ) 

`net.ipv4.ip_local_reserved_ports`의 시스템 매개변수를 설정하여 예약할 수 있으며, 예약된 포트는 자동으로 할당되지 않는다. 그러나 이는 O&M을 위해 시스템 제공을 더 어렵게 만들 수 있으므로 권장되지 않는다. 

그러니까 모든 유형의 애플리케이션 및 통신 프로토콜의 리스닝 포트는 표준화되어 9000 미만으로 설정하는게 좋다!

(쿠버네티스의 클러스터 ip의 할당 범위는 30000-32767이다)
<img width="728" height="44" alt="image" src="https://github.com/user-attachments/assets/988be341-0cd4-4bed-8798-d34b89f61e2e" />

## 3. 애플리케이션 서비스 포트와 관리 포트의 분리

서비스 포트는 비즈니스 요청 처리 포트이며, 관리 포트는 프레임워크 또는 애플리케이션을 위한 관리 요청 처리 포트이다. (ex: 서비스 등록 온라인/오프라인) Spring boot를 예로 들면, 애플리케이션 포트는 server.port에 해당되고 관리 포트는 management.port에 해당된다.

애플리케이션의 서비스 포트와 관리 포트를 분리하는 것은 다음과 같은 이점이 있다.
- 비즈니스 요청과 관리 요청이 서로 영향을 미치는 것을 방지한다. (ex. therad pulling)
- 권한 관리, ACL 제어를 가능하게 한다. 관리 포트는 일반적으로 애플리케이션의 핵심 동작을 제어할 수 있으므로, 엄격한 권한 관리 및 ACL 제어가 필요하다. (ex 방화벽을 통해 특정 포트에 액세스 하도록 허용)

비즈니스 애플리케이션의 HTTP 서비스 포트와 관리 포트가 동일하다고 치면, 애플리케이션의 동일한 인스턴스가 내부 논리 문제로 인해 교착 상태에 빠져  `the request blocking timeout`을 일으킨다. 하지만 이 때 서비스 등록 상태 유지 스레드는 여전히 정상이기 때문에, 클라이언트는 여전히 이 예외 인스턴스에 요청을 보내는 문제가 발새한다. 

이 시점에서 문제 해결을 위해 인스턴스를 시버스 등록에서 오프라인으로 전환하고, 프로세스를 유지해야 하지만, 비즈니스 스레드 차단으로 인해 HTTP thread pool의 모든 스레드가 차단되었고, 이는 관리 모듈 스레드가 HTTP 서비스 등록 오프라인 요청을 처리할 수 없게 하여, 결국 정상적으로 오프라인으로 전환할 수 없게 된다.

그래서 이러한 문제가 재발하는 것을 방지하기 위해 애플리케이션 서비스 포트와 관리 포트를 분리하고, 스레드 풀 격리를 구현해야 한다. 물론 Fusion 같은 다른 메커니즘도 개별 인스턴스를 예외 처리하는데 도움이 되지만, 포트 분리가 중점이다.

## 4. 연결 설정에 타임아웃 설정

네트워크 정체, IP 도달 불가능, 핸드셰이크 큐 가득 참 등의 상황에서 연결 설정이 차단되고 타임아웃될 수 있다. 앱에서 예측 불가능한 차단 시간을 피하기 위해, 타임아웃 제어를 위해 연결을 설정할 때 타임아웃 시간을 설정하는게 좋다. 능동적인 설정이 없다면, 타임아웃 시간은 시스템의 기본 동작에 의해 제어되는데 이는 모든 앱 시나리오에 충분하지 않을 수 있다. (참고: 핸드셰이크 큐가 가득 찼을 때 시스템 매개변수 `net.ipv4.tcp_abort_on_overflow`가 설정되어 있으면 연결이 즉시 리셋된다.) 

시스템이 기본적으로 연결 설정 타임아웃을 어떻게 제어하는지 살펴보자.

- TCP 3-way 핸드셰이크의 첫 번째 SYN 메시지가 ACK를 받지 못하면, 시스템은 자동으로 SYN 메시지를 재시도한다. 최대 재시도 횟수는 시스템 매개변수 **net.ipv4.tcp_syn_retries**에 의해 제어되며, 기본값은 6이다. 초기 RTO는 1초이며, SYN ACK를 받지 못하면 순서대로 1초, 2초, 4초, 8초, 16초, 32초를 기다린 후 재전송을 시작하고, 마지막 재전송은 64초를 기다린 후 포기한다. 결국 127초 후에 ETIMEOUT 타임아웃 오류를 반환한다.

<img width="703" height="48" alt="image" src="https://github.com/user-attachments/assets/b84d5f76-bc3c-42f5-b225-7efe836abc7d" />

특정 회사의 비즈니스 시나리오에 따라 `net.ipv4.tcp_syn_retries` 시스템 매개변수를 조정하여 보장하는 것이 좋다. (ex: 매개변수를 3으로 설정하여 최대 15초 내외에서 타임아웃 오류를 반환하도록 권장하는 의견)

## 5. 애플리케이션 계층 하트비트를 사용한 연결 상태 확인

TCP 연결에 예외가 발생하면, 우리는 가능한 빨리 이를 감지하고 이에 따라 예외를 처리하고 복구해야 한다. FIN 또는 RST와 같은 연결 종료 및 리셋 시나리오에서는 애플리케이션 계층에서 빠르게 감지할 수 있다. 그러나 피어 머신의 전원 차단, 네트워크 케이블의 물리적 분리, 네트워크 장비 이상으로 발생하는 `false connections`의 경우 특별한 조치가 없으면 애플리케이션 계층에서 오랫동안 감지하지 못할 수 있다.

네트워크 이상 감지와 관련하여 가장 먼저 떠오르는 것은 아마도 TCP Keepalive일 것이다. 시스템 TCP Keepalive와 관련된 세가지 매개변수는 `net.ipv4.tcp_keepalive_time, net.ipv4.tcp_keepalive_intvl, net.ipv4.tcp_keepalive_probes`이며 기본값은 각각 7200초, 75초, 9번이다. 즉, 7200초 동안 상대방으로부터 데이터를 받지 못하면 TCP Keepalive 메시지를 전송하기 시작하고, 75초 내에 응답이 없으면 모든 9번의 재시도가 실패할 때까지 재시도를 계속한 후 애플리케이션 계층 오류 메시지를 반환한다.

<img width="752" height="139" alt="image" src="https://github.com/user-attachments/assets/d2013be1-bf0d-472f-a817-62ca54062274" />

왜 애플리케이션 계층 하트비트 검사를 구현해야 할까? 시스템의 TCP Keepalive로는 요구 사항을 충족할 수 없을까? 그렇다. 시스템의 TCP Keepalive는 기본 방어 솔루션으로만 사용될 수 있으며, 높은 안정성과 높은 신뢰성 시나리오의 요구 사항을 충족할 수 없다. 그 이유는 다음과 같다.

- TCP Keepalive는 익스텐션 옵션으로, 모든 장치가 지원하지 않을 수 있다.
- TCP Keepalive 메시지는 캐리어 장비와 같은 장치에 의해 의도적으로 필터링되거나 차단될 수 있다.
- TCP Keepalive는 애플리케이션 계층 상태 (예: 프로세스 차단, 교착 상태, TCP 버퍼 가득 참 등)를 감지할 수 없다.
- TCP Keepalive는 TCP 재전송 제어와 충돌하기 쉬워 실패로 이어질 수 있다.

TCP 상태가 애플리케이션 계층 상태를 반영하지 않는 문제에 대해 간략히 설명한다. 첫 번째 시나리오는 TCP 연결 설정이 성공했다고 해서 상대방 애플리케이션이 연결을 감지했다는 의미가 아니다. 왜냐하면 TCP 3-way 핸드셰이크는 커널에서 완료되며, 연결이 설정되었더라도 상대방이 **Accept**를 전혀 하지 않았을 수도 있기 때문이다. 따라서 일부 시나리오에서는 TCP 연결이 성공적으로 설정될 수 있는지 여부만으로 상대방 애플리케이션의 상태를 판단하는 것은 정확하지 않으며, 이 시나리오로는 프로세스의 생존 여부만 감지할 수 있다. 

다른 시나리오는 로컬 TCP 쓰기 작업이 성공했지만, 데이터가 여전히 로컬 쓰기 버퍼, 네트워크 링크 장치 또는 상대방의 읽기 버퍼에 있을 수 있으며, 이는 상대방 애플리케이션이 데이터를 읽었다는 의미도 아니다.

여기서는 TCP Keepalive와 TCP 재전송 간의 충돌에 중점을 두자. Linux 시스템은 `net.ipv4.tcp_retries2` 매개변수를 통해 TCP 타임아웃 재전송 횟수를 제어하며, 이는 TCP 타임아웃 시간에 영향을 미친다. 초기 RTO는 TCP_RTO_MIN (200ms)이며, RTO는 지수적 양보를 하며, 최대 RTO는 TCP_RTO_MAX (2분)이다. net.ipv4.tcp_retries2의 기본값은 15이며, 대략 924.6초의 타임아웃을 의미한다.

<img width="653" height="47" alt="image" src="https://github.com/user-attachments/assets/a96865a2-9732-4c5d-8ba0-ffc183aefde9" />

TCP 전송 버퍼에 성공적으로 전송되지 않은 데이터가 있으면, TCP는 타임아웃 재전송을 수행하며 TCP Keepalive를 트리거하지 않는다. 즉, 앱이 `time=10s, interval=10s, probes=3` 와 같이 매우 작은 TCP Keepalive 매개변수를 설정하더라도 `net.ipv4.tcp_retries2` 기본 구성 하에서는 약 15분까지 기다려야 네트워크 예외를 감지할 수 있다. 일부 사람들은 Keepalive가 재전송에 의해 왜 간섭을 받는지 이해하지 못할 수 있지만, 실제로는 우선 순위 문제다. TCP 최대 재전송 횟수의 역할이 Keepalive 매개변수의 역할보다 높다. 최대 재전송 횟수에 도달하지 않으면 네트워크 오류 메시지가 애플리케이션 계층에 보고되지 않는다. 만약 Keepalive가 재전송에 영향을 받지 않는다면, 재전송에 관심 있는 사람들에게도 간섭을 줄 것이다. (ex: 최대 재전송 횟수에 도달하기 전에 왜 재전송이 포기되고 연결이 닫혔는가) 재 연결의 타이머 정보는 `netstat -ot` 또는 `ss -ot`명령으로 확인할 수 있다.

<img width="953" height="149" alt="image" src="https://github.com/user-attachments/assets/9c3b798c-187b-4557-acc0-f76a75dd7d53" />

실제 상황에 따라 `net.ipv4.tcp_retries2` 매개변수를 낮추는 것이 좋다. RFC 1122는 해당 타임아웃이 100초 이상, 즉 최소 8 이상이어야 한다고 권장하며, 일부 Zan 시스템에서는 기본값이 10으로 설정되어 있다.

따라서, 네트워크 탄력적인 애플리케이션을 달성하기 위해서는 애플리케이션 계층 하트비트가 필수적이다. HTTP2, gRPC, Dubbo 및 기타 프로토콜은 하트비트를 지원하므로, 애플리케이션이 이러한 프로토콜을 기반으로 개발된 경우 해당 프로토콜의 기능을 직접 사용하여 애플리케이션 계층 하트비트를 구현할 수 있다.

다만, 애플리케이션 계층 하트비트를 구현할 때 다음 사항을 고려해야 한다. 

- 하트비트 간격은 너무 작거나 너무 커서는 안된다. 간격이 너무 작으면 약간의 지터(Jitter)에 너무 민감하게 반응하여 과잉 반응을 일으킬 수 있으며, 이는 안정성에 영향을 미치고 성능 오버헤드도 발생시킬 수 있다. 간격이 너무 크면 이상 감지 지연 시간이 길어진다 하트비트는 엄격하게 정기적인 간격으로 전송되거나, 일정 기간 동안 상대방으로부터 데이터를 받지 못한 경우에만 시작될 수 있다. 권장되는 하트비트 간격은 5초 ~ 20초입다.
- 순간적인 지터로 인한 오분류 등을 방지하기 위해 연속 실패 임계값을 설정하라. 권장되는 연속 실패 임계값은 2 ~ 5이다.
- 하트비트 검사를 위해 독립적인 TCP 연결을 사용하지 마라. 왜냐하면 네트워크 경로, TCP 버퍼 등이 연결마다 다를 수 있으며, 이는 비즈니스 통신 연결의 진정한 상태를 반영하지 못하기 때문이다.

## 6. 연결 재연결에 후퇴 (Setback) 및 윈도우 지터 (Window Jitter) 추가 필요

네트워크 예외가 복구될 때, 많은 수의 클라이언트가 동시에 TCP 재연결을 시작하고 애플리케이션 계층 요청을 할 수 있으며, 이는 서버 측 과부하, 네트워크 대역폭 고갈과 같은 문제를 일으킬 수 있다. 이로 인해 클라이언트 연결 및 요청 처리가 실패하고, 클라이언트는 새로운 재시도를 트리거한다.후퇴 및 윈도우 지터 메커니즘이 없으면 상황이 계속될 수 있으며 빠르게 수렴하기 어렵다.

지수적 양보를 늘리는 것이 좋다 (예: 1초, 2초, 4초, 8초...). 동시에 최대 양보 시간은 제한되어야 한다. (예: 64초). 그렇지 않으면 재시도 대기 시간이 점점 커져서 빠른 수렴을 방해할 수 있다. 또한, 많은 수의 클라이언트가 동시에 연결을 설정하고 요청하는 것을 줄이기 위해 윈도우 지터를 늘려야 한다. 윈도우 크기는 양보 대기 시간과 일치시킬 수 있다.

지터가 뭐냐하면 타이밍에 무작위성(Randomness)을 부여하여 충돌을 분산시키는 기술이다. 네트워크 예외 상황에서 지터 없이 "1초 뒤에 다시 시도하세요"라고만 설정했다고 가정해보자.

1. 서버가 12시 정각에 down
2. 1,000명의 클라이언트가 동시에 에러를 본다.
3. 1,000명이 정확히 12:00:01에 동시에 재접속을 시도
4. 서버는 복구되자마자 다시 과부하로 죽어버린다.

이것을 동기화(Synchronization) 현상이라고 한다. 지터는 이들이 12:00:01.1, 12:00:01.5, 12:00:02.3 처럼 서로 다른 시간에 도착하도록 흩어지게 만드는 역할을 한다.

기본 대기 시간에 무작위 추가 시간을 더하는 방식으로 로직을 구현하면 된다. 지수적 백오프(Exponential Backoff)에 따라 정해진 시간에 무작위 계수를 생성하고, 그 값을 곱한 값에 기준 대기 시간의 0% ~ 100% 사이의 값을 추가로 더해준다. 그렇게 해주면 재시도 시간을 원래 대기 시간(N)에서 2배(2N) 사이의 구간으로 넓혀주는 공식이 완성된다. 예를 들어 `backOffWaitTime = 4` 라고 가정하면

1. 베스트 =
$$4 + (0.0 \times 4) = 4$$
2. 워스트 =
$$4 + (1.0 \times 4) = 8$$
3. 평균 =
$$4 + (0.5 \times 4) = 8$$

모든 클라이언트가 4초에 동시에 쏘는 게 아니라, 4초에서 8초 사이의 구간에 고르게 퍼져서 요청을 보내게 된다.

$$\text{nextRetryWaitTime} = \text{backOffWaitTime} + \text{rand}(0.0, 1.0) \times \text{backOffWaitTime}$$

마지막으로 네트워크 예외 테스트 또는 시연을 수행할 때, 네트워크 예외 시간 변수를 고려해야 한다. 지속 시간이 다르면 애플리케이션에 미치는 영향이 완전히 다를 수 있기 때문이다.

## 7. 서버 측은 최대 연결 수를 제한해야 한다.

서비스 포트가 받을 수 있는 이론적인 최대 TCP 연결 수는 얼마일까? TCP 4-튜플에서 서버 측 IP와 포트는 이미 고정되어 있으며, 이론적인 상한은 사용 가능한 클라이언트 측 IP 수 × 사용 가능한 클라이언트 측 포트 수이다. 일부 IP 분류, 포트 예약 등의 세부 사항을 제외하면 이론적 상한은 $2^{32} \times 2^{16} = 2^{48}$으로 계산된다.

물론 실무에서는 현재 이론적인 상한에 도달할 일은 거의 없다. TCP 소켓과 관련된 주요 리소스는 메모리 버퍼, 파일 디스크립터(FD) 등이다. 따라서 실제 한계는 주로 시스템 메모리 크기와 파일 디스크립터 한계에 따라 달라진다.

서버 측에서 최대 연결 수를 제한하는 주요 목적은 두 가지다.

- CPU 및 메모리 고갈로 이어지는 서비스 과부하를 방지
- 파일 디스크립터 고갈을 방지

TCP 연결의 각 소켓은 하나의 FD를 차지하며, 프로세스당 및 시스템 전체에 FD 수에 대한 제한이 있다. 모든 프로세스가 열 수 있는 최대 FD 수는 `cat /proc/sys/fs/file-max`에서 볼 수 있으며, 애플리케이션의 요구 사항을 충족하지 못하면 적절하게 조정해야 한다.

(현재 리눅스 커널 설정상, 시스템 전체의 파일 열기(네트워크 연결 포함) 제한이 이론상 최댓값(무한대)으로 설정되어 있어 있다.)

<img width="345" height="34" alt="image" src="https://github.com/user-attachments/assets/ae10366d-da48-4df6-ac20-ca7aedf22679" />

FD 한계에 도달하면 어떤 영향이 있을까? 첫째, 새로운 TCP 연결을 받는 것이 불가능해진다. 둘째, TCP 연결이 차지하는 FD 외에도, 애플리케이션 내부에는 새로운 FD를 할당하거나 필요로 하는 시나리오가 분명히 있다. 로그 파일 로테이션이 발생하여 새 로그 파일을 생성할 때, 로그 파일 생성이 실패하면 로컬 저장소에 의존하는 애플리케이션 (예: KV, MQ 및 기타 저장소 기반 애플리케이션)의 경우 서비스를 사용할 수 없게 만든다. 따라서 모든 FD를 클라이언트 TCP 연결에 사용하도록 제공하는 대신, 시스템 한계와 애플리케이션의 특성에 따라 일정 수의 FD를 예약 해야한다.

온라인 부하 테스트 중에 한 애플리케이션에서 유사한 문제가 발생할 수 있다. 부하 테스트 중에 압력이 비교적 높아서 디스크 IO 압력이 높아지고 요청 처리 지연이 높아져 클라이언트가 타임아웃되었다. 클라이언트는 타임아웃이 발생하면 연결을 닫고 새 연결을 생성하여 재시도했지만, 이 때 서버는 IO 차단으로 인한 지연 때문에 닫힌 연결의 소켓과 FD (CLOSE_WAIT)를 제때 회수할 수 없었고, 이로 인해 FD 소모가 점점 늘어난다. 결국 FD가 고갈되어 새 로그 파일 생성이 실패했고, 이 애플리케이션은 저장소 유형의 애플리케이션이었기 때문에 로그 디스크 드롭에 강하게 의존하여 결국 서비스를 사용할 수 없게 되는 것이다.

서버 측에서 최대 연결 수를 제한하는 것 외에도, 애플리케이션에 해당 클라이언트 SDK가 있다면, 클라이언트 SDK에서도 보호 계층을 수행하는 것이 가장 좋다.

## 8. 중앙 집중식 4계층 로드 밸런서에 의존하지 않도록 노력하자.

LVS(리눅스 버츄얼 서버)는 고전적인 중앙 집중식 4계층 로드 밸런싱 솔루션이며, 다양한 클라우드 공급업체에서도 LVS와 유사한 제품을 제공하며 대부분 원리가 동일하다. 이러한 유형의 솔루션을 사용하면 다음과 같은 문제에 직면할 수 있다.

1. 애플리케이션 용량을 확장할 때마다 백엔드 인스턴스 목록의 구성을 변경해야 하므로 O&M 비용과 위험이 높다.
2. 중앙 집중식 컴포넌트는 확장성이 낮고 병목 현상에 쉽게 도달한다 (예: 네트워크 대역폭 병목 현상).
3. 중앙 집중식 컴포넌트의 가용성이 낮아 로드 밸런서에 문제가 발생하면 전체 서비스가 영향을 받는다.
4. 4계층 상태 확인은 백엔드 인스턴스 이상에 둔감하며, 애플리케이션 수준의 상태 확인을 수행할 수 없다.
5. 로드 밸런서의 분할 및 마이그레이션은 애플리케이션에 더 큰 영향을 미치며, 업데이트된 구성, 릴리스 등과 협력해야 하므로 사용 비용이 더 많이 든다.
6. 로드 밸런서가 일정 기간 동안 통신하지 않은 유휴 연결을 끊을 수 있으며, 이는 애플리케이션에 의도하지 않은 영향을 미칠 수 있다.
7. 클라이언트가 서버에 액세스하려면 로드 밸런서를 통해 릴레이해야 하므로 RT (왕복 시간)에 약간의 영향을 미칠 수 있다.

중앙 집중식 로드 밸런싱 솔루션을 마이크로 서비스 아키텍처의 서비스 등록, 서비스 검색 및 로드 밸런싱 솔루션과 같은 분산 동적 서비스 등록 및 검색 및 클라이언트 측 로드 밸런싱으로 대체하는 것이 좋다.

중앙 집중식 로드 밸런서를 사용해야 하는 시나리오에서는 다음 문제도 주의해야 한다.

- 적절한 로드 밸런싱 알고리즘을 선택하여 장기 연결의 불균형한 분배를 방지하도록 주의해야 한다. 예를 들어, 폴링 로드 밸런싱 알고리즘을 선택하면 일반적인 상황에서 각 백엔드 인스턴스에 대한 연결 수는 균형을 이루지만, 인스턴스가 다시 시작되면 해당 인스턴스와의 연결이 끊긴 후 클라이언트가 재연결을 시작하고 재연결이 다른 인스턴스로 전달될 확률이 높아져 최근에 시작된 인스턴스에 대한 연결 수가 더 적고 가장 먼저 시작된 인스턴스에 대한 연결 수가 더 많아진다. 최소 연결 수 로드 밸런싱을 고려하거나, 장기 연결에 대한 TTL 제한을 늘리는 등을 고려할 수 있다.
- 유휴 타임아웃에 유의해야한다. 로드 밸런서가 타임아웃 후 양쪽 끝에 Close 또는 Reset 신호를 보내지 않아 통신할 수 없는 가짜 연결이 발생할 수 있다. 클라이언트와 서버 양쪽에서 하트비트, 유휴 타임아웃 등이 없으면 가짜 연결이 계속 존재하여 시스템 리소스를 차지한다.
- 백엔드 인스턴스를 제거할 때 원활함을 보장하도록 주의해야 한다. 백엔드 인스턴스를 직접 제거하면 양쪽 끝에 Close 또는 Reset 신호를 보내지 않을 수 있으며, 이로 인해 통신할 수 없고 클라이언트와 서버에서 제때 감지되지 않는 가짜 연결이 발생할 수 있다. 일반적으로 먼저 인스턴스 가중치를 0으로 조정하여 새 연결이 더 이상 인스턴스에 할당되지 않도록 한 다음, 기존 연결이 해제되기를 기다린 후 마지막으로 백엔드 인스턴스를 완전히 제거해야 한다.

## 9. 대량의 CLOSE_WAIT를 경계해야 한다.

어느 엔지니어의 사례: 온라인 환경 알림에서 높은 TCP 재전송이 있는 서버를 발견했으며, 패킷 캡처 분석 결과 재전송 패킷은 FIN 패킷이었고 대상 IP는 더 이상 존재하지 않았다. 연결 상태를 확인한 결과, 대량의 CLOSE_WAIT 상태 연결이 발견되었고, 문제는 항상 지속되는 것이 아니라 산발적이었다. 애플리케이션 로그 및 애플리케이션 코드를 분석한 결과, 시나리오 애플리케이션이 EOF를 읽을 때 로컬 소켓이 닫히지 않았음을 발견했다. 추가 분석 결과, 클라이언트 애플리케이션이 K8S에 의해 배포되며 릴리스 후 이전 인스턴스가 오프라인으로 전환되고, 클라이언트가 능동적인 연결 종료를 시작하며, 이전 인스턴스의 IP가 곧 재활용된다는 것을 알았다.  서버 측에서 닫히지 않은 소켓은 몇 분 후에 GC (Go 언어 애플리케이션)가 소켓 회수 종료 작업을 수행하기 전에 닫히지만, 이 시점에서는 클라이언트 IP가 더 이상 존재하지 않으므로 마지막 FIN 메시지는 최대 재전송 횟수를 초과할 때까지 계속 재전송되며, 이로 인해 문제가 해결된다.

클라이언트 애플리케이션이 다시 릴리스되면 문제가 다시 나타난다. GC 메커니즘이 없는 프로그래밍 언어로 개발된 애플리케이션의 경우, 소켓이 계속 누출되어 FD 고갈 및 메모리 부족과 같은 문제로 이어질 수 있으므로 문제가 더 심각한 결과를 초래할 수 있다. 

따라서, 대량의 CLOSE_WAIT 상태 연결이 나타나는 것을 반드시 경계해야 하며, 이러한 상황이 발생하면 먼저 관련 코드를 배제해야 한다. 동시에 개발 프로세스 중에 소켓을 올바르게 닫는 것에 주의해야 한다. Go의 `defer`, Java의 `try...catch...finally`, C++의 `RAII` 메커니즘 등과 같은 일부 언어 기능을 사용하여 보장할 수 있다.

## 10. 장기 연결 TTL을 합리적으로 설정해야 한다.

장기 연결은 3-way 핸드셰이크 오버헤드, 느린 시작 오버헤드 등과 같은 단기 연결처럼 빈번한 연결 설정 오버헤드를 줄인다. 그러나 특정 단점이 있다. 장기 연결 지속 시간이 너무 길면, 일부 로드 밸런싱 문제 및 장기간에 걸쳐 수렴하기 어려운 기타 문제로 이어질 수 있다. 예를 들어, LVS 시나리오에서 백엔드 애플리케이션 인스턴스가 다시 시작됨에 따라, 일부 로드 밸런싱 알고리즘 (예: 폴링)의 경우 가장 최근에 시작된 인스턴스에 대한 연결 수가 가장 적고 가장 먼저 시작된 인스턴스에 대한 연결 수가 가장 많은 결과를 초래한다. 일부 클라이언트 측 로드 밸런싱 솔루션의 경우, 백엔드 클러스터의 단일 노드만 연결해야 하는 시나리오 (예: Etcd watch와 유사한 시나리오)와 같은 장기 연결에서 유사한 문제가 발생한다.) 물론 Etcd를 사용하는 많은 시나리오가 있으며, 초기 O&M은 Etcd 클러스터를 변경할 때마다 연결 불균형을 피하기 위해 특히 신중해야 한다.

모든 애플리케이션의 TCP 장기 연결 TTL이 2시간을 초과할 수 없도록 규정하는 게 좋다. 물론 이것은 이미 매우 보수적인 길이이며, 애플리케이션 시나리오에 따라 TTL을 합리적으로 설정하는 것이 좋다.

## 11. 도메인 이름을 통한 서비스 액세스는 정기적인 DNS 해석이 필요하다.

DNS는 서비스 검색 메커니즘이며, 애플리케이션은 도메인 이름을 구성하여 다른 서비스에 액세스한다. 이는 다른 서비스 인스턴스의 IP 변경 영향을 해결하기 위한 것이지만, 제대로 처리하지 않으면 여전히 문제가 될 수 있다. 도메인 이름을 통해 다른 서비스에 액세스할 때는 정기적으로 도메인 이름 해석을 업데이트하고, 해석에 업데이트가 있는 경우 연결을 다시 설정하여 백엔드 인스턴스가 마이그레이션될 때 (IP가 변경된 경우) 수렴의 어려움을 피해야한다. 애플리케이션이 시작될 때 한 번만 도메인 이름 해석을 수행해서는 안된다. 이 경우, DNS 변경 후 빠른 수렴을 달성하려면 모든 관련 애플리케이션을 다시 시작하거나 릴리스해야한다. 일부 언어에는 DNS 관련 구현이 내장되어 있으므로 해당 매개변수와 동작이 예상대로인지 주의해야 한다.

또한, Etcd 및 Redis와 같은 일부 애플리케이션은 최신 클러스터 멤버 목록을 가져오는 인터페이스를 제공하므로, 클라이언트가 하나의 도메인 이름 해석으로 시작하더라도 서버 측에서 서비스 클러스터 멤버 목록을 정기적으로 동기화하는 한 서버 측 클러스터 멤버의 동적 변경을 지원할 수 있다.

## 12. 네트워크 읽기/쓰기 시스템 호출 횟수 줄이기

소켓에서 데이터를 읽거나 쓰기 위해 read/write 시스템 함수를 호출할 때, 각 호출은 사용자 및 커널 상태 간에 최소 두 번의 컨텍스트 전환을 수행하며, 이는 비교적 비용이 많이든다. 이 문제에 대한 일반적인 최적화 아이디어는 두 가지다. 

1. 읽기/쓰기 버퍼 사용: 데이터를 읽을 때, 먼저 소켓에서 버퍼로 한 번에 읽은 다음, 필요에 따라 버퍼에서 단계적으로 읽는다. 데이터를 쓸 때, 먼저 버퍼에 단계적으로 쓴 다음, 버퍼가 가득 차거나 모든 쓰기 작업이 완료되면 소켓에 한 번에 쓴다.
2. 데이터를 연속된 메모리로 병합하기가 편리하지 않을 때, `readv / writev`를 사용하여 여러 메모리 세그먼트의 데이터를 한 번에 읽거나 쓴다.

대량 쓰기 작업의 또 다른 이점은 Nagle 알고리즘으로 인한 지연을 피할 수 있다는 것이다. (일반적으로 Nagle 알고리즘을 켜는 것은 권장되지 않는다.) 현재 쓰기 버퍼에 데이터가 없는 경우, 먼저 write를 통해 4바이트를 쓰면 TCP 스택이 이를 전송한다. 그런 다음 write를 통해 96바이트를 쓴다. 이 때, 이전에 메시지가 전송되었으므로 ACK가 수신되지 않았고, 현재 전송 가능한 데이터가 MSS에 도달하지 않았으므로, Nagle 알고리즘은 추가 메시지 전송을 허용하지 않으며, 이전 메시지의 ACK가 돌아올 때까지 기다린 다음 데이터를 계속 전송해야 한다. 이는 처리량을 크게 줄이고 지연 시간을 늘린다. 수신 측에서 지연 ACK가 켜져 있으면 영향은 더욱 커진다.

따라서 성능 향상을 위해 네트워크 데이터를 대량으로 읽고 쓰는 것을 시도해야 한다.

13. TCP 버퍼 크기를 신중하게 설정해야 한다.

일반적으로 TCP 기본 버퍼 크기를 변경할 필요는 없지만, 설정해야 하는 경우 신중하게 고려하고 평가해야 한다. 

적절한 TCP 버퍼 크기는 얼마일까? 알려진 바와 같이, TCP의 전송 속도는 송신 및 수신 윈도우 크기와 네트워크 용량에 의해 제한된다. 두 윈도우는 버퍼 크기에 의해 결정되며, 버퍼 크기가 네트워크 용량과 일치하면 버퍼 활용도가 가장 높다.

`대역폭-지연 곱 (Bandwidth-delay Product, BDP)`*은 네트워크 전송 용량을 설명하는 데 사용된다. 최대 대역폭이 100MB/s이고 네트워크 지연이 10ms인 경우, 클라이언트와 서버 간의 네트워크는 총 $$100MB/s /time 0.01s=1MB$$ 바이트를 저장할 수 있으며, 이 1MB는 대역폭과 지연의 곱, 즉 BDP이다. 이 1MB 바이트는 네트워크 라인 및 라우터와 같은 네트워크 장치에 있는 전송 중인 TCP 메시지를 위해 존재한다. 전송 중인 메시지가 1MB를 초과하면 확실히 네트워크에 과부하가 걸리고 결국 패킷 손실로 이어진다.

송신 버퍼는 송신 윈도우의 상한을 결정하며, 이는 다시 전송되었지만 아직 승인되지 않은 전송 중인 메시지의 상한을 결정한다. 따라서 송신 버퍼는 BDP를 초과할 수 없다. 초과분은 효율적인 네트워크 전송에 사용할 수 있는 방법이 없으며, BDP보다 큰 전송 중인 바이트는 패킷 손실로 이어져 네트워크 혼잡 회피를 트리거한다. 또한 버퍼는 BDP보다 작아서도 안 된다. 그렇지 않으면 고속 네트워크의 가치를 끌어낼 수 없다.

요약하자면: 너무 작은 버퍼는 TCP 처리량을 줄이고, 네트워크 대역폭을 효율적으로 사용하지 못하게 하며, 통신 지연을 높인다. 너무 큰 버퍼는 TCP 연결의 높은 메모리 사용량을 초래하고, BDP에 의해 제한되는 병목 현상이 발생하여 메모리 낭비로 이어진다. 버퍼가 너무 작으면 (예: 2K), 빠른 재전송이 적용되지 않을 수도 있다. 승인되지 않은 메시지가 최대 2개만 있을 수 있으며, 3개의 중복 ACK가 없을 수 있기 때문이다. 

Linux 시스템은 시스템 상태에 따라 버퍼 크기를 자동으로 조정할 수 있으며, 관련 매개변수는 `net.ipv4.tcp_wmem` 및 `net.ipv4.tcp_rmem`에 의해 제어된다. 이 매개변수는 3-튜플 (최소, 초기 기본, 최대)지만, 그러나 소켓에서 직접 `SO_SNDBUF` 또는`SO_RCVBUF`를 설정하면 시스템의 동적 버퍼 조정 기능이 꺼진다. 이를 수행하기 전에 전체 평가를 수행하는 것이 중요하다. 

<img width="384" height="82" alt="image" src="https://github.com/user-attachments/assets/9923b90c-322e-4afd-914d-19425dfdde47" />

따라서 필요성을 매우 명확히 이해하고 충분한 평가 및 검증을 수행하지 않는 한, TCP 버퍼 크기를 쉽게 설정하면 안된다.

## 14. 네트워크 관련 매개변수가 유연한 구성을 지원하도록 하자

애플리케이션에 여러 배포 환경 및 시나리오가 있을 수 있는 경우, 사용 시나리오 및 네트워크 환경 등에 따라 적절한 네트워크 관련 매개변수를 조정해야 한다. LAN과 WAN의 네트워크 조건은 매우 다르며, 이는 많은 매개변수의 조정을 수반한다. 

만약 사이드카 배포 시나리오와 공용 네트워크 게이트웨이 교차 배포 시나리오가 둘다 있으면, 필요에 따라 해당 매개변수를 조정 해야한다. 그렇지 않으면 다른 네트워크 환경에 적응하기 어렵다. 예를 들어, 연결 타임아웃, 읽기/쓰기 타임아웃, 상태 확인 타임아웃, 상태 확인 실패 임계값 등은 모두 유연한 구성을 지원 해야한다.

## 15. 커넥션 풀 크기를 합리적으로 설정해야 한다.

연결 풀은 프로토콜 유형에 따라 다르게 설계된다. 우리는 프로토콜이 연결 다중화를 지원하는지 여부에 따라 비-다중화 프로토콜과 다중화 프로토콜의 두 가지 범주로 분류한다.

- 비-다중화 프로토콜: 연결이 요청을 보내고 응답이 돌아올 때까지 기다려야만 새 요청을 보낼 수 있는 프로토콜 (예: HTTP1.1, Redis).
- 다중화 프로토콜: 동일한 연결이 동시에 여러 요청을 보내는 것을 지원하는 프로토콜 (예: HTTP2, gRPC, Dubbo).

먼저 비-다중화 프로토콜에 대한 연결 풀 크기를 설정하는 방법을 살펴보자. 연결 풀에 관련된 매개변수는 일반적으로 최소 연결 수, 최대 연결 수, 최대 유휴 시간, 연결 확보 타임아웃, 연결 확보 타임아웃 재시도 횟수 등이다. 애플리케이션과 연결 풀 간의 주요 상호 작용 논리는 다음과 같습니다.

주로 최소 연결 수와 최대 연결 수에 대해 논의합니다. 연결 수가 고정되지 않는 이유는 트래픽에 피크와 밸리가 있기 때문이다. 고정 연결 수가 너무 적으면 피크 트래픽 기간 동안 요청 대기 시간이 너무 길어지고, 고정 연결 수가 너무 많으면 낮은 트래픽 기간 동안 리소스가 낭비된다. 따라서 최소 연결 수는 낮은 트래픽 기간 동안 적절한 연결 수에 해당하며, 최대 연결 수는 피크 트래픽 기간 동안 적절한 연결 수에 해당한다. 즉, 연결 수는 트래픽 크기와 관련이 있다. 트래픽 크기 외에도 `요청 RT (각 요청이 걸리는 시간)`를 고려해야 한다. 필요한 연결 수는 실제로 동시 요청 수이며, 여기서 유명한 `Little의 법칙 (L=λW)`을 사용하여 계산할 수 있다. 예를 들어, 낮은 트래픽 기간 요청 QPS가 100이고 요청 RT가 0.05초이면, 동시성은 5이고 필요한 연결 수는 5이다. 피크 트래픽 기간... 이 유형의 문제는 실제로 대기열 이론과 관련이 있지만 더 복잡한 요구 사항 시나리오가 있는 경우 더 많은 대기열 이론 관련 자료를 참조할 수 있다.

다음으로 다중화 프로토콜이 연결 풀 크기를 설정하는 방법을 살펴보자. 연결 풀에 관련된 매개변수는 일반적으로 최소 연결 수, 최대 연결 수, 단일 연결 동시 요청에 대한 상한 수위표(high water mark), 단일 연결 동시 요청에 대한 하한 수위표(low water mark) 등 이다. 단일 연결에 대한 동시 요청 수가 상한 수위표보다 높으면, 연결 풀이 최대 연결 수에 도달하지 않은 경우 연결 풀이 확장되고 연결이 생성된다. 단일 연결에 대한 동시 요청 수가 하한 수위표보다 낮으면, 연결 풀이 최소 연결 수에 도달하지 않은 경우 연결 풀이 축소되고 연결이 해제된다. (해제 프로세스는 원활해야 한다) 각 요청이 연결을 독점하지 않으므로, 요청은 모든 연결을 선택할 수 있다. 

따라서 여기에서도 로드 밸런싱 문제가 발생하며, 각 연결에서 처리되는 요청 수가 평균에 최대한 가깝도록 보장해야 한다. 일반적으로 최소 요청 로드 밸런싱이 사용되지만, 최소 요청 로드 밸런싱의 시간 복잡도가 높을 수 있으며 가장 간단한 구현은 전체 연결 풀을 스캔해야한다. 무작위로 두 연결을 선택하고 가장 낮은 Pending 요청 수를 가진 연결을 선택하여 근사 최적화 구현을 사용할 수 있다. 최소 요청에 더 가깝게 근사하려면 3개, 5개 또는 그 이상의 연결을 선택하고 가장 낮은 Pending 요청 수를 가진 연결을 선택할 수 있다. 

## 16. 네트워크 메트릭 모니터링 개선

다음과 같은 다양한 주요 네트워크 메트릭에 대한 모니터링 및 경고가 필요하다.

- TCP 연결 설정 실패 횟수
- TCP 메시지 재전송 속도
- 각 상태의 TCP 연결 수 (특히 ESTABLISHED, TIME_WAIT, CLOSE_WAIT)
- TCP 능동 연결 종료 횟수
- TCP 수동 연결 종료 횟수
- 연결 상태 확인 실패 횟수
- 시스템 및 프로세스 FD 사용량
- 연결 풀 크기

이러한 지표의 이상을 조기에 감지할 수 있다면 문제를 가능한 빨리 식별하여 문제의 영향을 줄일 수 있다.

